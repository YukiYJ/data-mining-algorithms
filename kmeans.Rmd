---
title: "kmeans"
author: "MA Mingyu 14110562D"
date: "4/4/2017"
output:
  pdf_document: default
  html_document: default
---
#COMP4433 Assignment 2 Question 3 a, b and c
##derek.ma@connect.polyu.hk [derek.ma](http://derek.ma)

#Set Up
Import data, delete first column, set initial cluster centers to first two records
```{r setup, include=TRUE}
library(dplyr)
#PREPARE DATA IN USE
data_original <- read.csv("~/Google Drive/_DM/2_Assignments/Ass2/data_q3.csv", stringsAsFactors = FALSE)
#delete first column for this specific case becasue it is not a data record
data_original <- data_original[,2:length(colnames(data_original))]
#SET VALUE OF K
data <- data_original
#SET INITIAL CLUSTER CENTERS
centers <- data[0,]
```

#Data Preprocessing and Normalization
```{r preprocessing}
#Normalization
min1 <- min(data$B)
max1 <- max(data$B)
min2 <- min(data$C)
max2 <- max(data$C)
min3 <- min(data$D)
max3 <- max(data$D)
min4 <- min(data$E)
max4 <- max(data$E)
min5 <- min(data$F)
max5 <- max(data$F)
min6 <- min(data$G)
max6 <- max(data$G)

data_normalized <- data %>%
  mutate(BN = (B - min1)/(max1-min1)) %>%
  mutate(CN = (C - min2)/(max2-min2)) %>%
  mutate(DN = (D - min3)/(max3-min3)) %>%
  mutate(EN = (E - min4)/(max4-min4)) %>%
  mutate(FN = (F - min5)/(max5-min5)) %>%
  mutate(GN = (G - min6)/(max6-min6))

data_normalized<-data_normalized[,c(7,8,9,10,11,12)]
colnames(data_normalized) <- c("B","C","D","E","F","G")
data <- data_normalized
centers <- data[c(1,2),]
```

# Basic Function 1 - Distance Function
In this case, Euclidean Distance is used to calculate the dissimilarities.
```{r distance}
distance <- function(vector1, vector2){
  #Euclidean distance
  #Input: two vectors of data with same length
  #Input example: c(1,2,3); c(2,3,4)
  count <- 0
  for (i in 1:length(vector1)){
    count = count + (vector1[i] - vector2[i])^2
  }
  count^(1/2)
}
distance2 <- function(vector1, vector2){
  #Euclidean distance
  #Input: two vectors of data with same length
  #Input example: c(1,2,3); c(2,3,4)
  count <- 0
  for (i in 1:length(vector1)){
    count = count + (vector1[i] - vector2[i])^2
  }
  count
}
```

# Basic Function 2 - Compare Similarity and Assign Objects to Clusters
In this function, each record can be decivded belong to which clusters.
```{r assignObject}
assign <- function(objectsData, centersData){
  #OUTPUT a data frame with new cluster information
  #FOR EACH RECORDS
  result <- objectsData %>% 
    mutate(cluster = NA)
  for (i in 1:nrow(objectsData)){
    whichCenter <- 0
    currentMinDist <- -1
    #COUNT DISSIMILARITY BETWEEN IT AND CENTERS
    for (j in 1:nrow(centersData)){
      distValue <- distance(
        as.numeric(objectsData[i,]),
        as.numeric(centersData[j,]))
      if (distValue < currentMinDist || whichCenter == 0){
        #FOUND CENTER WITH SMALLER DISSIMILARITY
        whichCenter <- j
        currentMinDist <- distValue
      }
    }
    #SET THIS CENTER AS CLUSTER
    result[i,"cluster"] <- whichCenter
  }
  result
}
```

# Basic Function 3 - Calculate Mean Values of Objects and Update Centers
In this function, the centers will be updated to the mean of clustered objects.
```{r updateCenters}
update <- function(objectsData, centersData){
  #INPUT  objectsData: the data frame with original data and corresponding cluster information
  #INPUT  centersData: all last round data for all centers
  #OUTPUT a data frame with new centers
  #FOR EACH CENTER
  result <- centersData
  for (i in 1:nrow(centersData)){
    #GET ALL NODES IN THIS CLUSTER
    clusterData <- subset(objectsData, objectsData[,"cluster"] == i)
    #CALCULATE MEAN FOR EACH FEATURE & UPDATE CENTERS
    for (j in 1:ncol(centersData)){
      result[i,j] <- mean(clusterData[,j])
    }
  }
  result
}
```

#Question 3a
##First Round
Run the algorithm for the first time.
```{r firstRound}
data1 <- assign(data, centers)
data1
centers1 <- update(data1, centers)
centers1
```
We can find that some data records are devided to belong to cluster 1 and others are belong to cluster 2. Update the centers.

##Second Round
Run the alogrithm for the second time.
```{r secondRound}
data2 <- assign(data, centers1)
data2
centers2 <- update(data2, centers1)
centers2
```
There are some changes for centers and cluster distribution. Update the centers again.

##Third Round
Then run the algorithm for the third time.
```{r thirdRound}
data3 <- assign(data, centers2)
data3
centers3 <- update(data3, centers2)
centers3
```
We can find that the centers are not changed. Thus all objects are divided into two clusters and the final clustering result is already got. The clustering result is:

##Result
```{r result}
result_2 <- data3
data3 %>% select(cluster)
centers3
```

#Question 3b
## First Round
```{r firstRound-b}
centers <- data[c(13,14,15),]
data1 <- assign(data, centers)
data1
centers1 <- update(data1, centers)
centers1
```

## Second Round
```{r secondRound-b}
data2 <- assign(data, centers1)
data2
centers2 <- update(data2, centers1)
centers2
```

## Third Round
```{r thirdRound-b}
data3 <- assign(data, centers2)
data3
centers3 <- update(data3, centers2)
centers3
```

## Fourth Round
```{r fourthRound-b}
data4 <- assign(data, centers3)
data4
centers4 <- update(data4, centers3)
centers4
```

## Fifth Round
```{r fifthRound-b}
data5 <- assign(data, centers4)
data5
centers5 <- update(data5, centers4)
centers5
```

## Sixth Round
```{r sixthRound-b}
data6 <- assign(data, centers5)
data6
centers6 <- update(data6, centers5)
centers6
```
We can found the coordinates for centers and cluster distrbution are not changed from round 5 to round 6. Thus we can terminate the iteration and find out the result:

## Result
```{r result-b}
result_3 <- data6
data6 %>% select(cluster)
centers6
```

# Question 3c
Calculate the CH index for the clustering result from (a) and (b), the performance should be better for the one with higher CH index.

## Funcion - calculate within cluster variation
```{r withinFunction}
withinClusterVariation <- function(objectsData){
  result <- rep(NA,length(unique(objectsData$cluster)))
  for (clusterIndex in unique(objectsData$cluster)){
    temp <- subset(objectsData, cluster==clusterIndex)
    center <- rep(NA,ncol(objectsData)-1)
    for (i in 1:(ncol(objectsData)-1)){
      center[i] <- mean(temp[,i])
    }
    temp <- temp[,1:6]
    sum <- 0
    for (i in 1:nrow(temp)){
      sum <- sum + distance2(center,as.numeric(temp[i,]))
    }
    result[clusterIndex] <- sum
  }
  sum(result)
}
```

## Funcion - calculate between cluster variation
```{r betweenFunction}
betweenClusterVariation <- function(objectsData){
  result <- rep(NA,length(unique(objectsData$cluster)))
  center <- rep(NA,ncol(objectsData)-1)
  for (i in 1:(ncol(objectsData)-1)){
    center[i] <- mean(objectsData[,i])
  }
  for (clusterIndex in unique(objectsData$cluster)){
    temp <- subset(objectsData, cluster==clusterIndex)
    center1 <- rep(NA,ncol(objectsData)-1)
    for (i in 1:(ncol(objectsData)-1)){
      center1[i] <- mean(temp[,i])
    }
    sum <- 0
    for (i in 1:nrow(temp)){
      sum <- sum + distance2(center,center1)
    }
    result[clusterIndex] <- sum
  }
  sum(result)
}
```
## Calculate CH Index
```{r chindex}
w2 <- withinClusterVariation(result_2)
w3 <- withinClusterVariation(result_3)
b2 <- betweenClusterVariation(result_2)
b3 <- betweenClusterVariation(result_2)
ch_2 <- ((b2/(2-1))/(w2/(15-2)))
ch_3 <- ((b3/(3-1))/(w3/(15-3)))
w2
w3
ch_2
ch_3
```

## Result
CH index for `k=2` is 31.65 which is small than CH index for `k=3`'s 36.42. For within cluster variation, `k=2` is larger than `k=3`. These two index both show that the performance of `k=3` is better than `k=2`.

```{r verification, include=FALSE}
library(datasets)
verify <- kmeans(data,center=data[c(1,2),])
verify
```